# ğŸ—ï¸ Blue Tech - Construction Materials Price Tracker

Sistema integral para el seguimiento y anÃ¡lisis de precios de materiales de construcciÃ³n a nivel global.

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [ConfiguraciÃ³n](#ï¸-configuraciÃ³n)
- [Uso](#-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Fuentes de Datos](#-fuentes-de-datos)
- [Mejoras Implementadas](#-mejoras-implementadas)
- [Contribuir](#-contribuir)
- [Licencia](#-licencia)

## âœ¨ CaracterÃ­sticas

### Dashboard Interactivo
- ğŸ—ºï¸ **VisualizaciÃ³n en mapa mundial** con cÃ³digos ISO-3
- ğŸ“Š **GrÃ¡ficos comparativos** entre paÃ­ses y regiones
- ğŸ’± **ConversiÃ³n automÃ¡tica a USD** con tasas actualizadas
- ğŸ” **Filtros dinÃ¡micos** por material, paÃ­s y moneda
- ğŸ“ˆ **AnÃ¡lisis estadÃ­stico** con mÃ©tricas clave
- ğŸ“¥ **ExportaciÃ³n de datos** en formato CSV

### Web Scraping Robusto
- ğŸ¤– **Scraping automatizado** de mÃºltiples fuentes
- âœ… **ValidaciÃ³n de datos** completa
- ğŸ’¾ **Backup automÃ¡tico** de datos anteriores
- ğŸ“ **Logging detallado** de todas las operaciones
- ğŸ”„ **Manejo de errores** y reintentos
- ğŸ§¹ **Limpieza automÃ¡tica** de backups antiguos

### Arquitectura Mejorada
- ğŸ¯ **ConfiguraciÃ³n centralizada** en mÃ³dulo separado
- ğŸ—ï¸ **CÃ³digo modular** y fÃ¡cil de mantener
- ğŸ“š **DocumentaciÃ³n completa** en cada funciÃ³n
- ğŸ§ª **Preparado para testing** con estructura clara
- ğŸŒ **Soporte multiidioma** (ES/EN)

## ğŸ“¦ Requisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- 4GB RAM mÃ­nimo
- ConexiÃ³n a internet (para scraping)

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/your-org/blue-tech-materials.git
cd blue-tech-materials
```

### 2. Crear entorno virtual

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno

```bash
# Copiar el template
cp .env.example .env

# Editar .env con tus configuraciones
nano .env  # o usa tu editor preferido
```

### 5. Crear estructura de directorios

```bash
mkdir -p data/backups logs
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

El archivo `.env` contiene las siguientes configuraciones clave:

```env
# Paths
DATA_FILE=data/material_prices.csv
BACKUP_DIR=data/backups
LOG_DIR=logs

# Scraping
REQUEST_TIMEOUT=30
REQUEST_DELAY=1
MAX_RETRIES=3

# Dashboard
CACHE_TTL=3600
LOG_LEVEL=INFO
```

### Tasas de Cambio

Las tasas de cambio se actualizan regularmente en `config.py`. Para mayor precisiÃ³n, considera integrar una API de tasas de cambio en tiempo real.

## ğŸ“– Uso

### 1. Recolectar Datos (Scraping)

```bash
python material_scraper_improved.py
```

Este comando:
- âœ… Recolecta datos de todas las fuentes configuradas
- âœ… Valida y limpia los datos
- âœ… Crea backup de datos anteriores
- âœ… Guarda los resultados en `data/material_prices.csv`
- âœ… Genera logs detallados en `logs/`

### 2. Visualizar Dashboard

```bash
streamlit run material_dashboard_improved.py
```

El dashboard se abrirÃ¡ automÃ¡ticamente en tu navegador en:
```
http://localhost:8501
```

### 3. Programar Ejecuciones AutomÃ¡ticas

#### Linux/Mac (usando cron)

```bash
# Editar crontab
crontab -e

# Ejecutar scraping diariamente a las 6 AM
0 6 * * * /path/to/venv/bin/python /path/to/material_scraper_improved.py
```

#### Windows (usando Task Scheduler)

1. Abrir "Programador de tareas"
2. Crear tarea bÃ¡sica
3. Configurar trigger (ej: diariamente)
4. AcciÃ³n: Iniciar programa
   - Programa: `C:\path\to\venv\Scripts\python.exe`
   - Argumentos: `C:\path\to\material_scraper_improved.py`

## ğŸ“ Estructura del Proyecto

```
blue-tech-materials/
â”œâ”€â”€ material_dashboard_improved.py   # Dashboard Streamlit mejorado
â”œâ”€â”€ material_scraper_improved.py     # Scraper con validaciÃ³n y logs
â”œâ”€â”€ config.py                        # ConfiguraciÃ³n centralizada
â”œâ”€â”€ requirements.txt                 # Dependencias de Python
â”œâ”€â”€ .env.example                     # Template de configuraciÃ³n
â”œâ”€â”€ .gitignore                       # Archivos a ignorar en Git
â”œâ”€â”€ README.md                        # Este archivo
â”‚
â”œâ”€â”€ data/                           # Datos recolectados
â”‚   â”œâ”€â”€ material_prices.csv         # Datos actuales
â”‚   â””â”€â”€ backups/                    # Backups automÃ¡ticos
â”‚       â””â”€â”€ material_prices_backup_*.csv
â”‚
â”œâ”€â”€ logs/                           # Archivos de log
â”‚   â”œâ”€â”€ scraper.log                 # Log del scraper
â”‚   â””â”€â”€ app_*.log                   # Logs diarios
â”‚
â”œâ”€â”€ sources/                        # MÃ³dulos de fuentes de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ static_data.py              # Datos estÃ¡ticos
â”‚   â”œâ”€â”€ numbeo_global.py            # Scraper de Numbeo
â”‚   â””â”€â”€ [future_scrapers].py        # Futuros scrapers
â”‚
â””â”€â”€ tests/                          # Tests unitarios (futuro)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_dashboard.py
    â””â”€â”€ test_scraper.py
```

## ğŸ”Œ Fuentes de Datos

### Actuales

1. **StaticDataSource** - Datos pre-configurados de referencia
2. **NumbeoGlobalScraper** - Precios globales de Numbeo

### Futuras (Expandibles)

- Amazon Construction Materials
- Home Depot API
- Local Hardware Stores
- Government Statistics Portals
- Industry Reports

Para agregar una nueva fuente:

1. Crear mÃ³dulo en `sources/`
2. Implementar mÃ©todos `fetch_prices()` y `format_data()`
3. Agregar a la lista en `material_scraper_improved.py`

## ğŸ”§ Mejoras Implementadas

### VersiÃ³n Mejorada vs Original

| Aspecto | Original | Mejorado |
|---------|----------|----------|
| Encoding | âŒ Caracteres corruptos | âœ… UTF-8 correcto |
| Error Handling | âš ï¸ BÃ¡sico | âœ… Try-catch completo |
| Logging | âŒ Print bÃ¡sico | âœ… Sistema profesional |
| ValidaciÃ³n | âš ï¸ MÃ­nima | âœ… ValidaciÃ³n completa |
| Backups | âŒ No implementado | âœ… AutomÃ¡tico |
| ConfiguraciÃ³n | âŒ Hardcoded | âœ… Externalizada |
| Tasas de Cambio | âš ï¸ Desactualizadas | âœ… Actualizadas 2026 |
| DocumentaciÃ³n | âš ï¸ Comentarios bÃ¡sicos | âœ… Docstrings completos |
| Tests | âŒ No existe | âœ… Estructura preparada |
| DeduplicaciÃ³n | âŒ No implementado | âœ… AutomÃ¡tica |

### Nuevas CaracterÃ­sticas

1. **Sistema de Backup**
   - Backup automÃ¡tico antes de sobrescribir
   - Limpieza de backups antiguos
   - Conserva Ãºltimos 10 backups

2. **ValidaciÃ³n de Datos**
   - Verifica campos requeridos
   - Valida precios positivos
   - Detecta datos corruptos
   - Elimina duplicados

3. **Logging Profesional**
   - Logs en archivo y consola
   - Niveles configurables
   - RotaciÃ³n automÃ¡tica
   - Timestamps detallados

4. **EstadÃ­sticas Detalladas**
   - Resumen por fuente
   - MÃ©tricas de calidad
   - Tiempos de ejecuciÃ³n
   - Tasa de Ã©xito

5. **ConfiguraciÃ³n Flexible**
   - Variables de entorno
   - Config centralizado
   - FÃ¡cil customizaciÃ³n
   - No hardcoded values

## ğŸ§ª Testing (PrÃ³ximamente)

```bash
# Ejecutar todos los tests
pytest

# Con coverage
pytest --cov=. --cov-report=html

# Ver reporte
open htmlcov/index.html
```

## ğŸ“Š MÃ©tricas de Rendimiento

- **Tiempo de scraping:** ~30-60 segundos (depende de fuentes)
- **Dashboard load time:** <3 segundos con cache
- **Capacidad de datos:** Hasta 100,000 registros
- **Memoria RAM:** ~200MB en uso normal

## ğŸ› SoluciÃ³n de Problemas

### Error: "Data file not found"

```bash
# Ejecutar el scraper primero
python material_scraper_improved.py
```

### Error: "Module not found"

```bash
# Reinstalar dependencias
pip install -r requirements.txt
```

### Dashboard no carga

```bash
# Verificar puerto
netstat -ano | findstr :8501

# Usar puerto alternativo
streamlit run material_dashboard_improved.py --server.port 8502
```

### Logs no se generan

```bash
# Crear directorio manualmente
mkdir logs

# Verificar permisos (Linux/Mac)
chmod 755 logs
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add: AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### GuÃ­a de Estilo

- Seguir PEP 8
- Docstrings en todas las funciones
- Type hints cuando sea posible
- Tests para nuevas features

## ğŸ“ Changelog

### v2.0.0 (Enero 2026) - MEJORADA
- âœ… Sistema de logging profesional
- âœ… ValidaciÃ³n completa de datos
- âœ… Backups automÃ¡ticos
- âœ… ConfiguraciÃ³n externalizada
- âœ… DocumentaciÃ³n completa
- âœ… Fix encoding issues
- âœ… Tasas de cambio actualizadas
- âœ… EstadÃ­sticas mejoradas

### v1.0.0 (Original)
- âœ… Dashboard bÃ¡sico
- âœ… Scraper bÃ¡sico
- âš ï¸ Sin validaciÃ³n robusta
- âš ï¸ Sin backups

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Blue Tech Team** - *Desarrollo inicial y mejoras*

## ğŸ™ Agradecimientos

- Streamlit por el framework de dashboard
- Plotly por las visualizaciones
- Numbeo por los datos pÃºblicos
- Comunidad open source

## ğŸ“ Contacto

- ğŸ“§ Email: contact@bluetech.com
- ğŸŒ Website: https://bluetech.com
- ğŸ’¬ Discord: https://discord.gg/bluetech

---

**Hecho con â¤ï¸ por Blue Tech**

*Ãšltima actualizaciÃ³n: Enero 2026*
